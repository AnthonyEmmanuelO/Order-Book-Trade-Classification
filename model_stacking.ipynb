{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (9,4)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import random\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "import category_encoders as ce\n",
    "from scipy.stats import zscore\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#model validation / evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2df(cm, labels): \n",
    "    \"\"\"converts a numpy array confusion matrix to a pandas dataframe, with class labels\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    # rows\n",
    "    for i, row_label in enumerate(labels):\n",
    "        rowdata={}\n",
    "        # columns\n",
    "        for j, col_label in enumerate(labels): \n",
    "            rowdata[col_label]=cm[i,j]\n",
    "        df = df.append(pd.DataFrame.from_dict({row_label:rowdata}, orient='index'))\n",
    "    return df[labels]\n",
    "\n",
    "def model_eval(y_test, y_pred): \n",
    "    \"\"\"prints out a confusion matrix (pandas dataframe) and classification report\"\"\"\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    cm_as_df=cm2df(conf_mat,[0,1])\n",
    "    new_names = {0:'Order Fail',1:'Order Success'}\n",
    "    cm_as_df = cm_as_df.rename(index=new_names, \n",
    "                                 columns=new_names)\n",
    "    print('\\n')\n",
    "    print('CONFUSION MATRIX (predicted along top, actual along side): ')\n",
    "    display(cm_as_df)\n",
    "\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test,y_pred,target_names=['Order Fail','Order Success']))\n",
    "    \n",
    "def cross_validation(model, features, response, num_folds):\n",
    "    metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "    cv = cross_validate(model, features, response, scoring=metrics, cv=num_folds)\n",
    "    print(\"Test data set average precision across 5 folds:\")\n",
    "    print(cv['test_precision_macro'])\n",
    "    print(\"\\nTest data set average recall across 5 folds:\")\n",
    "    print(cv['test_recall_macro'])\n",
    "    print(\"\\nTest data set average fscore across 5 folds:\")\n",
    "    print(cv['test_f1_macro'])\n",
    "    \n",
    "def plot_roc_curve(model, X_test, y_test):\n",
    "    probabilities = model.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, probabilities)\n",
    "    print('AUC: %.3f' % auc)\n",
    "\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "    # plot no skill curve\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    success = df[df['ordersuccess']==1]\n",
    "    fail = df[df['ordersuccess']==0]\n",
    "\n",
    "    success_num = len(success)\n",
    "    fail_num = len(fail)\n",
    "    total = len(df)\n",
    "\n",
    "    print('Number of order successes: ', success_num)\n",
    "    print('Proportion of order successes: ', success_num / (success_num + fail_num))\n",
    "    print('Number of order failures: ', fail_num)\n",
    "    print('Proportion of order failures: ', fail_num / (success_num + fail_num))\n",
    "    print('\\n')\n",
    "    \n",
    "    def getTimeMS(t):\n",
    "        if '.' in t:\n",
    "            timestamp, ms = t.split('.')\n",
    "        else:\n",
    "            timestamp = t\n",
    "            ms = 0\n",
    "        time_obj = datetime.strptime(timestamp, '%H:%M:%S')\n",
    "        epoch = datetime(1900, 1, 1, 0, 0, 0, 0)\n",
    "        milliseconds = (time_obj - epoch) // timedelta(milliseconds=1)\n",
    "        return milliseconds + float(ms)*1000\n",
    "\n",
    "    df['time_ms'] = df['starttime'].apply(lambda x: getTimeMS(x))\n",
    "    df['adv20d'] = df.loc[:,'adv20d'].fillna(0)\n",
    "\n",
    "\n",
    "    #continuous features\n",
    "    cont_features = df.loc[:,['time_ms','size','minexecqty','limitprice','prevailbid','prevailask','prevailbidsize','prevailasksize',\n",
    "                              'dispatcherrebalance','lotsize','averagespread','misavgbidsize1min','misavgasksize1min', \n",
    "                              'misavgspread1min', 'misoddlotvolume1min', 'misadfvolume1min','misvolume1min', 'adv20d']]\n",
    "\n",
    "    #one-hot encoded features\n",
    "    dummies = pd.get_dummies(df.loc[:,['side','venuetype','securitycategory', 'peginstruction',\n",
    "                                       'sector','mktcap']].astype('category'),drop_first=True)\n",
    "\n",
    "    #binary encoded features\n",
    "    enc = ce.BinaryEncoder()\n",
    "    binary_sym = enc.fit_transform(df.loc[:,'symbol'].values)\n",
    "    names = {'0_0':'symbol_0', '0_1':'symbol_1','0_2':'symbol_2','0_3':'symbol_3','0_4':'symbol_4',\n",
    "             '0_5':'symbol_5','0_6':'symbol_6','0_7':'symbol_7','0_8':'symbol_8','0_9':'symbol_9',\n",
    "             '0_10':'symbol_10','0_11':'symbol_11','0_12':'symbol_12'}\n",
    "    binary_sym = binary_sym.rename(columns=names)\n",
    "\n",
    "    binary_venue = enc.fit_transform(df.loc[:,'venue'].values)\n",
    "    names = {'0_0':'venue_0', '0_1':'venue_1','0_2':'venue_2',\n",
    "             '0_3':'venue_3','0_4':'venue_4','0_5':'venue_5','0_6':'venue_6'}\n",
    "    binary_venue = binary_venue.rename(columns=names)\n",
    "\n",
    "\n",
    "    features = pd.concat([cont_features, dummies, binary_sym, binary_venue], axis=1)\n",
    "    response = df.loc[:,'ordersuccess']\n",
    "\n",
    "    df = pd.concat([features,response],axis=1)\n",
    "    \n",
    "    df = df.sample(frac=1)\n",
    "    train = df.head(round(total*.70))\n",
    "    train = train.reset_index(drop=True)\n",
    "    cont_features = ['time_ms','size','minexecqty','limitprice','prevailbid','prevailask','prevailbidsize','prevailasksize',\n",
    "                          'dispatcherrebalance','lotsize','averagespread','misavgbidsize1min','misavgasksize1min', \n",
    "                          'misavgspread1min', 'misoddlotvolume1min', 'misadfvolume1min','misvolume1min', 'adv20d']\n",
    "    scaler = StandardScaler().fit(train.loc[:,cont_features])\n",
    "    Z_train = pd.DataFrame(scaler.transform(train.loc[:, cont_features]))\n",
    "    train_categories = train[train.columns[~train.columns.isin(cont_features)]]   \n",
    "    train_Z = pd.concat([Z_train, train_categories], axis=1)\n",
    "    \n",
    "    \n",
    "    test = df.tail(round(total*.30))\n",
    "    test = test.reset_index(drop=True)\n",
    "    Z_test = pd.DataFrame(scaler.transform(test.loc[:, cont_features]))\n",
    "    test_categories = test[test.columns[~test.columns.isin(cont_features)]]   \n",
    "    test_Z = pd.concat([Z_test, test_categories], axis=1)\n",
    "    \n",
    "\n",
    "    train_success = train[train['ordersuccess']==1]\n",
    "    train_success = train_success.reset_index(drop=True)\n",
    "    train_fail = train[train['ordersuccess']==0]\n",
    "    \n",
    "    train_Z_success = train_Z[train_Z['ordersuccess']==1]\n",
    "    train_Z_success = train_Z_success.reset_index(drop=True)\n",
    "    train_Z_fail = train_Z[train_Z['ordersuccess']==0]\n",
    "    \n",
    "    return train, train_fail, train_success, test, train_Z, train_Z_fail, train_Z_success, test_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_iterations(train, train_fail, train_success, test, train_Z, train_Z_fail, train_Z_success, test_Z):\n",
    "    def train_model(train_fail, train_success,  train_Z_fail, train_Z_success, sample):\n",
    "        downsampled_fails = train_fail.loc[sample,:]\n",
    "        downsampled_fails_Z = train_Z_fail.loc[sample, :]\n",
    "        \n",
    "        #recombine and shuffle data\n",
    "        train_downsampled = pd.concat([downsampled_fails, train_success],axis=0)\n",
    "        train_downsampled = train_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "        train_Z_downsampled = pd.concat([downsampled_fails_Z, train_Z_success], axis=0)\n",
    "        train_Z_downsampled = train_Z_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        #split into x and y\n",
    "        train_features = train_downsampled.loc[:,train_downsampled.columns != 'ordersuccess']\n",
    "        train_response = train_downsampled.loc[:,'ordersuccess']\n",
    "        train_features_Z = train_Z_downsampled.loc[:,train_Z_downsampled.columns != 'ordersuccess']\n",
    "        train_response_Z = train_Z_downsampled.loc[:,'ordersuccess']\n",
    "\n",
    "        #train models\n",
    "        RF = RandomForestClassifier()\n",
    "        RF.fit(train_features, train_response)\n",
    "        \n",
    "        LR = AdaBoostClassifier(LogisticRegression())\n",
    "        LR.fit(train_features, train_response)\n",
    "        \n",
    "        ANN = MLPClassifier()\n",
    "        ANN.fit(train_features_Z, train_response_Z)\n",
    "        \n",
    "        NB = MultinomialNB()\n",
    "        NB.fit(train_features, train_response)\n",
    "        return RF, LR, ANN, NB\n",
    "\n",
    "    train_features = train.loc[:,train.columns != 'ordersuccess']\n",
    "    test_features = test.loc[:,test.columns != 'ordersuccess']\n",
    "    test_features = test_features.reset_index(drop=True)\n",
    "    train_features_Z = train_Z.loc[:,train_Z.columns != 'ordersuccess']\n",
    "    test_features_Z = test_Z.loc[:,test_Z.columns != 'ordersuccess']\n",
    "    test_features_Z = test_features_Z.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    new_features_train = pd.DataFrame({})\n",
    "    new_features_test = pd.DataFrame({})\n",
    "    indices_used = set()\n",
    "    total_indices_train_fails = train_fail.index.tolist()\n",
    "    successes = len(train_success)\n",
    "    iterations = 0\n",
    "    while len(indices_used) < 0.8*len(train_fail):\n",
    "        iterations+=1\n",
    "        sample = random.sample(total_indices_train_fails, len(train_success))\n",
    "        indices_used.update(sample)\n",
    "        RF, LR, ANN, NB = train_model(train_fail, train_success, train_Z_fail, train_Z_success, sample)\n",
    "        \n",
    "        #RF\n",
    "        y_pred_train = pd.DataFrame(RF.predict(train_features))\n",
    "        y_pred_train = y_pred_train.rename(columns={0:\"RF Model %s\" %iterations})\n",
    "        new_features_train = pd.concat([new_features_train, y_pred_train], axis=1)\n",
    "        y_pred_test = pd.DataFrame(RF.predict(test_features))\n",
    "        y_pred_test = y_pred_test.rename(columns={0:\"RF Model %s\" %iterations})\n",
    "        new_features_test = pd.concat([new_features_test, y_pred_test], axis=1)\n",
    "        \n",
    "        #LR\n",
    "        y_pred_train = pd.DataFrame(LR.predict(train_features))\n",
    "        y_pred_train = y_pred_train.rename(columns={0:\"LR Model %s\" %iterations})\n",
    "        new_features_train = pd.concat([new_features_train, y_pred_train], axis=1)\n",
    "        y_pred_test = pd.DataFrame(LR.predict(test_features))\n",
    "        y_pred_test = y_pred_test.rename(columns={0:\"LR Model %s\" %iterations})\n",
    "        new_features_test = pd.concat([new_features_test, y_pred_test], axis=1)\n",
    "        \n",
    "        #ANN\n",
    "        y_pred_train = pd.DataFrame(ANN.predict(train_features_Z))\n",
    "        y_pred_train = y_pred_train.rename(columns={0:\"ANN Model %s\" %iterations})\n",
    "        new_features_train = pd.concat([new_features_train, y_pred_train], axis=1)\n",
    "        y_pred_test = pd.DataFrame(ANN.predict(test_features_Z))\n",
    "        y_pred_test = y_pred_test.rename(columns={0:\"ANN Model %s\" %iterations})\n",
    "        new_features_test = pd.concat([new_features_test, y_pred_test], axis=1)\n",
    "        \n",
    "        #NB\n",
    "        y_pred_train = pd.DataFrame(NB.predict(train_features))\n",
    "        y_pred_train = y_pred_train.rename(columns={0:\"NB Model %s\" %iterations})\n",
    "        new_features_train = pd.concat([new_features_train, y_pred_train], axis=1)\n",
    "        y_pred_test = pd.DataFrame(NB.predict(test_features))\n",
    "        y_pred_test = y_pred_test.rename(columns={0:\"NB Model %s\" %iterations})\n",
    "        new_features_test = pd.concat([new_features_test, y_pred_test], axis=1)\n",
    "        \n",
    "        if iterations*4 % 16 == 0:\n",
    "            print('Trained %s models' %(iterations*4))\n",
    "\n",
    "    print('Total iterations', iterations)\n",
    "    train_features = pd.concat([train_features, new_features_train], axis=1)\n",
    "    test_features = pd.concat([test_features, new_features_test], axis=1)\n",
    "\n",
    "    train_response = train.loc[:,'ordersuccess']\n",
    "    test_response = test.loc[:,'ordersuccess']\n",
    "    test_response = test_response.reset_index(drop=True)\n",
    "    \n",
    "    return train_response, test_response, new_features_train, new_features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of order successes:  28190\n",
      "Proportion of order successes:  0.05021044213331149\n",
      "Number of order failures:  533247\n",
      "Proportion of order failures:  0.9497895578666885\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv('data.csv')\n",
    "    train, train_fail, train_success, test, train_Z, train_Z_fail, train_Z_success, test_Z = preprocess(df)\n",
    "    train_response, test_response, new_features_train, new_features_test = model_iterations(train, train_fail, \n",
    "                                                                                            train_success, test, train_Z, \n",
    "                                                                                            train_Z_fail, train_Z_success, \n",
    "                                                                                            test_Z)\n",
    "    \n",
    "    RF = RandomForestClassifier()\n",
    "    RF.fit(new_features_train, train_response)\n",
    "\n",
    "    #select top 10 features\n",
    "    important_features = sorted(zip(map(lambda x: round(x, 4), RF.feature_importances_), \n",
    "                                    new_features_train.columns), reverse=True)[0:10]\n",
    "    print('IMPORTANT FEATURES SELECTED BY RANDOM FOREST:', important_features)\n",
    "    \n",
    "    names = []\n",
    "    for i in important_features:\n",
    "        names.append(i[1])\n",
    "\n",
    "    AB = AdaBoostClassifier(LogisticRegression())\n",
    "    AB.fit(new_features_train.loc[:, names], train_response)\n",
    "    y_pred = AB.predict(new_features_test)\n",
    "    model_eval(test_response, y_pred)\n",
    "\n",
    "    plot_roc_curve(AB, new_features_test, test_response)\n",
    "    \n",
    "    features = pd.concat([new_features_train, new_features_test], axis=0)\n",
    "    response = pd.concat([train_response, test_response], axis=0)\n",
    "    cross_validation(AB, features, response, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB = AdaBoostClassifier(LogisticRegression())\n",
    "# AB.fit(new_features_train, train_response)\n",
    "# y_pred = AB.predict(new_features_test)\n",
    "# model_eval(test_response, y_pred)\n",
    "# plot_roc_curve(logreg, new_features_test, test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.07, 'Model 13'), (0.0635, 'Model 29'), (0.0615, 'Model 31'), (0.0441, 'Model 14'), (0.0439, 'Model 35'), (0.0439, 'Model 22'), (0.0395, 'Model 20'), (0.0372, 'Model 6'), (0.036, 'Model 10'), (0.0339, 'Model 25')]\n"
     ]
    }
   ],
   "source": [
    "# RF = RandomForestClassifier()\n",
    "# RF.fit(train_model_pred, train_response)\n",
    "\n",
    "# #select top n features\n",
    "# important_features = sorted(zip(map(lambda x: round(x, 4), RF.feature_importances_), \n",
    "#                                 train_model_pred.columns), reverse=True)[0:10]\n",
    "# print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC with Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = []\n",
    "# for i in important_features:\n",
    "#     names.append(i[1])\n",
    "    \n",
    "# clf = svm.LinearSVC().fit(train_model_pred.loc[:, names], train_response) #linear kernel function\n",
    "# y_pred = clf.predict(test_model_pred.loc[:, names])\n",
    "# model_eval(test_response, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfANN = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
    "#            beta_1=0.95, beta_2=0.9995, early_stopping=False,\n",
    "#            epsilon=1e-05, hidden_layer_sizes=(100, 100),\n",
    "#            learning_rate='constant', learning_rate_init=0.01,\n",
    "#            max_iter=3000, momentum=0.9,\n",
    "#            nesterovs_momentum=True, power_t=0.5, random_state=0,\n",
    "#            shuffle=True, solver='adam', tol=0.001,\n",
    "#            validation_fraction=0.1, verbose=True, warm_start=False)\n",
    "\n",
    "\n",
    "# clfANN.fit(train_model_pred, train_response)\n",
    "# y_pred = clfANN.predict(test_model_pred)\n",
    "# # y_pred = (clfANN.predict_proba(test_model_pred)[:,1] >= 0.1).astype(bool) #adjust classification threshold\n",
    "\n",
    "# model_eval(test_response, y_pred)\n",
    "# plot_roc_curve(clfANN, test_model_pred, test_response)\n",
    "# # cross_validation(clfANN, features, response, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
